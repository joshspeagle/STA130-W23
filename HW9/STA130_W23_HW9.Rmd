---
title: "STA130 Rstudio Homework **Solutions**"
author: "[Student Name] ([Student Number]), with Josh Speagle & Scott Schwartz"
subtitle: Problem Set 9
urlcolor: blue
output:
  pdf_document: default
---

```{r, include=FALSE}
knitr::opts_chunk$set(eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE)
```

```{r}
student_num =   # list your student number
student_num_last3 =   # list the last three digits of your student number
```

# Instructions

Complete the exercises in this `.Rmd` file and submit your `.Rmd` and knitted `.pdf` output through [Quercus](https://q.utoronto.ca/courses/296457) by 11:59 pm E.T. on Thursday, March 30.

# Question 0: Ethics in Data Science

A number of ethical concerns often arise when conducting research with people. Consider the following two situations.

\
**(a)** A data analyst receives permission to post a data set that was scraped from a social media site, provided it is appropriately "de-idenfitied" (i.e. ensure that each entry cannot be linked to a specific individual). The full data set included:

- name,
- screen name,
- email address, 
- geographic location, 
- IP (internet protocol) address, 
- demographic profiles, and 
- preferences for relationships. 

The researcher believes just removing the name and email address should be enough to de-identify the data. Are they correct? If not, what issues might still be present?

*Note: This question is taken from Section 8.12, Problem 8 in "Modern Data Science with R (2nd edition)".*

> *REPLACE THIS TEXT WITH YOUR ANSWER*


\
**(b)** A reporter carried out a clinical trial of chocolate where a small number of overweight subjects who had received medical clearance were randomized to either eat dark chocolate or not to eat dark chocolate. They were followed for a period and their change in weight was recorded from baseline until the end of the study. More than a dozen outcomes were recorded and one proved to be significantly different in the treatment group than the outcome. This study was publicized and received coverage from a number of magazines and television programs. What are some of the potential ethical considerations that could arise in this situation?

*Note: This question is adapted from Section 8.12 Problem 5 in "Modern Data Science with R (2nd edition)".*

> *REPLACE THIS TEXT WITH YOUR ANSWER*

Could there be additional statistical concerns due to the fact that only a small number of subjects were included in the study and a large number of outcomes were tracked and recorded? Why or why not?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

# Introduction to Lumosity

For the remainder of the assignment we will focus specifically on some of the more subtle (or perhaps not so subtle) ways in which various issues can impact our results and/or our interpretation of our results. Note that most of the analysis methods should be very closely related to methods and code you have implemented in previous problem sets, and so the difficulty/length of these questions should be quite a bit easier/shorter than they might appear at first glance if you can take full advantage of your past work.

[*Lumosity*](https://www.lumosity.com/en/) is a brain training app that claims to help improve cognitive skills such as memory, reasoning and focus. A large randomized trial was conducted to evaluate the impact of Lumosity training on cognitive skills. The study and results are presented in [Hardy et al. (2015)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0134467)'s publication *"Enhancing Cognitive Abilities with Comprehensive Training: A Large, Online, Randomized, Active-Controlled Trial"*.

In the study, thousands of participants were recruited from Lumosity's free users (i.e., people who set up free Lumosity accounts but did not pay for full access) and randomly assigned to one of two groups:

- **Treatment Group** (Lumosity Training): Participants in the treatment group completed Lumosity training online for approximately 15 minutes at a time, at least 5 times a week for 10 weeks.
- **Control Group** (Crossword Puzzles): Participants in the control group completed crossword puzzles online for approximately 15 minutes at a time, at least 5 times a week for 10 weeks.

Looking at the main differences between the two groups, the main variable being tested was whether doing Lumosity training exercises on a regular basis were more effective than the "baseline" activity of doing crosswords for roughly the same amount of time and at the same frequency. In other words, it's not trying to measure whether Lumosity training is better than *nothing*, but whether it's better than another simple yet popular activity (crossword puzzles) that many people do on a regular basis. Note that regular crossword puzzle solving has itself been associated with numerous claims of improved cognitive performance and have also been studied in quite some detail, which is likely one reason why it was used as a control activity for this study.

Let's now load in the data.

```{r}
library(tidyverse)

# load in the data
study_dat <- 
  read_csv("lumosity_study_data.csv") %>%
  na.omit()
glimpse(study_dat)
```

This data set contains information on the 5045 Lumosity users who participated in the study. The main measure of cognitive skills was called the Grand Index (GI) Score, and higher GI values imply better cognitive skills. The cognitive skills of the participants who completed the study were scored before and after the 10-week study period, with the difference recorded as the `GI_improve` variable.

Let's visualize the distribution of the `GI_improve` values between the two groups now.

```{r, message=FALSE}
# generate summary table
group_by(study_dat, group) %>%
  summarise(n=n(),
            mean=mean(GI_improve), 
            sd=sd(GI_improve),
            median=median(GI_improve),
            IQR=IQR(GI_improve)
            )

# generate grouped boxplot comparison
study_dat %>%
  ggplot() +
  aes(x=GI_improve, fill=group) +
  geom_histogram(position="identity", alpha=0.5)
```

Several other potentially useful variables from the study are also included including the participants' ages (`age_round`), ability to concentrate ranked from 1-5 (`concentration_post`), and the number of active days participating in study activities (`active_days`).

# Question 1: Lumosity, Crosswords, and Cognitive Performance

Let's now investigate the central question of the study: does the impact of Lumosity training differ from that provided by solving crossword puzzles?

\
**(OPTIONAL) (a)** Perform a **two-sample permutation hypothesis test** using $m=1000$ trials to compare whether the **mean** Grand Index score improvements after online training (`GI_improve`) between the `lumosity` ($n=2667$) and `crosswords` ($2378$) groups are the *same* (null hypothesis) or *different* (alternative hypothesis) using an $\alpha=0.05$ rejection rule. Plot your resulting sampling distribution and also print out your computed p-value and the result of your hypothesis test after applying your rejection rule.

*Hint: Your code from HW4 may be helpful here!*

```{r}
set.seed(student_num_last3)  # required to ensure reproducibility

# code your answer here

```

\
**(b)** Based on your 2-sample permutation test above, **you should have found that the estimated p-value is 0** (or extremely close to it) and therefore rejected the null hypothesis in favour of the alternative. This naively implies that there is very strong evidence against the null hypothesis that the mean Grand Index Score improvement is the same for those undergoing Lumosity training and those completing online crossword puzzles.

Do you believe this result? If so, why? If not, why not?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

\
**(OPTIONAL) (c)** Use **bootstrapping** with $m=1000$ trials to estimate the 95% **confidence interval** for the true population mean of `GI_improve` for the populations associated with each of the groups (`lumosity` and `crosswords`).

*Hint: Your code from HW5 may be helpful here!*

```{r}
set.seed(student_num_last3 + 1)  # required to ensure reproducibility

# code your answer here

```

Comment on whether your estimated 95% CIs support or weaken the results of your two-sample hypothesis test.

> *REPLACE THIS TEXT WITH YOUR ANSWER*

# Question 2: Study Design

Outside of any potential issues you may have discussed above, there might also be issues with the inherent study design used by Hardy et al. (2015).

\
**(a)** Take a look at Figure 1 from the [Hardy et al. (2015)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0134467) paper, which summarizes their study design. In 1-3 sentences, describe what this figure tells us about how the study was performed and what data was eventually used for the comparison we made earlier.

> *REPLACE THIS TEXT WITH YOUR ANSWER*

\
**(b)** Is the data we analyzed above (and got a p-value of $0$ for) the full data of a randomized controlled trial? Or a subset of data that is based on individual behavior (and hence in some sense "observational")?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

\
**(c)** With these pieces of information in mind, can we conclusively conclude based on these results that Lumosity training leads to more improvement in cognitive skills compared with completing crossword puzzles online? Explain your answer in 1-3 sentences.

> *REPLACE THIS TEXT WITH YOUR ANSWER*

# Question 3: Two Groups, Multiple Variables

There are multiple additional variables provided as part of the dataset. These may serve as **confounding variables** that also correlate with `GI_improve`. If the general distribution of these variables differs between the two groups, that might explain some (or potentially *all*) of the observed effect.

**(a)** Let's first consider the participants' ages, as recorded by `age_round`. We might expect that a participant's age correlates with their overall ability to improve their cognitive skills (e.g., older participants may benefit more than younger participants). Do you think user ages would be different between the Lumosity group and crossword groups? Why or why not?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

**(b)** Produce appropriate data summaries/visualizations to see if:

1. the ages (`age_round`) of the users correlates with their Grand Index score differences (`GI_improve`) and
2. whether the ages differ for the Lumosity and crossword groups (`group`).

*Hint: Your code from HW2 may be helpful here!*

```{r}
# code your answer below

```

Interpret your summary and comment on how this compares to your prediction about how ages would compare.

> *REPLACE THIS TEXT WITH YOUR ANSWER*

**(c)** What about the other two variables, `concentration_post` and `active_days`? What effects might these have on `GI_improve`? And would we expect to potentially see differences in their distributions across the two samples?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

**(d)** Produce appropriate data summaries/visualizations to see if either of these variables correlates with `GI_improve` and/or if their distributions appear to differ between the two groups.

*Hint: Your code from HW2 may be helpful here!*

```{r}
# code your answer below

```

# Question 4: Predictions with Multiple Variables

While data visualizations can be useful in diagnosing any obvious issues, a more rigorous way to explore them involves fitting a model that can account for potential effects explicitly.

\
**(a)** Let's first explore a simple **linear regression** model. Using the `lm()` function, fit a linear regression model that uses all of the variables available (`group`, `age_round`, `concentration_post`, and `active_days`) **excluding interaction terms**. The print out a summary of the model using `summary()`.

*Hint: Your code from HW7 may be helpful here!*

```{r}
# code your answer below

```

What is particular coefficient that we can use to test for potential differences in the mean `GI_improve` values between the two samples? Based on the reported test statistic and p-value for this coefficient (from a $t$-test), should we reject the null hypothesis under the same $\alpha$ significance level as above?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

Is there anything potentially concerning about the above results? If so, what?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

\
**(b)** Repeat the above analysis, but now using a model that **includes all possible interaction terms** (i.e. with the syntax `x1 * x2 * x3 * x4`).

*Hint: Your code from HW7 may be helpful here!*

```{r}
# code your answer below

```

How do these results compare to your previous ones? Is this surprising? Does it suggest anything regarding the potential impact of confounding variables? If so, why? If not, why not?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

\
**(c)** Repeat the above analysis, but now using a **decision tree**. After loading in the `rpart` and `partykit` packages, train a decision tree *using the entire dataset* (i.e. without partitioning it into separate training/validation/testing sets). Then, visualize the resulting tree along with the feature importances.

*Note: Using a decision tree this way for a regression problem just involves switching out the loss function to be the mean-squared-error (MSE) and the predictions to be the sample mean of objects within each node, rather than using the Gini impurity as the loss function and having the predictions be the fraction of objects in a given class within each node. This should happen automatically if you use the syntax `rpart(GI_improve ~ x1 + x2)` based on the data type of `GI_improve`.*

*Hint: Your code from HW8 may be helpful here!*

```{r}
library(rpart)
library(partykit)

set.seed(student_num_last3 + 2)  # required to ensure reproducibility

# code your answer below

```

How do these results compare to your previous ones? Is this surprising? How might this relate to some of the potential issues with decision trees, such as how splits are calculated, potential splitting rules, and/or issues such as overfitting?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

\
**(d)** Repeat the above analysis, but now using a **random forest**. After loading in the `randomForest` package, train a random forest *using the entire dataset* (i.e. without partitioning it into separate training/validation/testing sets). Then, plot a visualization showing the predicted feature importances.

*Note: As with the decision tree, the random forest should automatically adjust the loss function and prediction method based on the data type of the input variable (`GI_improve`) even though the input syntax of `randomForest(GI_improve ~ x1 + x2)` is otherwise identical.*

*Hint: Your code from HW8 may be helpful here!*

```{r}
library(randomForest)

set.seed(student_num_last3 + 3)  # required to ensure reproducibility

# code your answer below

```

How do these results compare to your previous ones? Is this surprising? How might this relate to some of the ways in which random forests potentially address some of the shortcomings of decision trees?

> *REPLACE THIS TEXT WITH YOUR ANSWER*

\
**(e)** Based on the above results, what is your overall opinion on whether the impact of Lumosity training on cognitive skills differs from the impact of solving crossword puzzles?

> *REPLACE THIS TEXT WITH YOUR ANSWER*
